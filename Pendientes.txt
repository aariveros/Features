Pendientes

1. Es necesario normalizar las confianzas en el caso de la matriz de confusion??

2. Análisis de las nuevas Features. Basicamente graficar confianza y evolución de la feature y ver como se comportan.

3. Log de errores: en get_feat_progress no se registran los errores que hay en las curvas. Debería registrar el id de las curvas que fallan. 

4. En graf_feature agregar opcion de si se quiere mostrar y/o guardar los graficos generados.

5. Acelerar stetsonJ con operaciones vectoriales.

6. Agregar cython a los metodos de las features

7. a futuro se podria considerar la distancia al corte de los puntos. Nose si es buena idea, los arboles normales no lo hacen

8. Agregar pruning basado en una cantidad o porcentaje minimo de tuplas para seguir partiendo un nodo

9. Probar otros tipos de indices

10. Usar k-fold de scikit

11. Tengo que volver a samplear las features. Hay algunas curvas que samplee con el metodo antiguo que estan sampleadas 
	muy pocas veces. 

12. Hacer graficos que verifiquen que las features con mayor grado de confianza se encuentran mas cerca de su valor final.

13. sanity check. Si resultados son malos, ir eliminando las features que veamos que su valor esta lejos
	del valor que debiera tener. Si las eliminamos, deberiamos comprobar que el f score aumenta

14. Agregar parametros al arbol que regulen su comportamiento. Ejemplo profundidad maxima.

15. Prunning del arbol

16. Que pasa si simplemente ajustamos una gaussiana a los valores que a tomado la feature?? Y hacemos que el árbol funcione con distribuciones de probabilidades