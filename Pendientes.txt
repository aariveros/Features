Pendientes

1. Es necesario normalizar las confianzas en el caso de la matriz de confusion??

2. Análisis de las nuevas Features. Basicamente graficar confianza y evolución de la feature y ver como se comportan.

3. Log de errores: en get_feat_progress no se registran los errores que hay en las curvas. Debería registrar el id de las curvas que fallan. 

4. En graf_feature agregar opcion de si se quiere mostrar y/o guardar los graficos generados.

5. Acelerar stetsonJ con operaciones vectoriales.

6. Agregar cython a los metodos de las features

7. a futuro se podria considerar la distancia al corte de los puntos. Nose si es buena idea, los arboles normales no lo hacen

9. Probar otros tipos de indices

11. Tengo que volver a samplear las features. Hay algunas curvas que samplee con el metodo antiguo que estan sampleadas 
	muy pocas veces. 

12. Hacer graficos que verifiquen que las features con mayor grado de confianza se encuentran mas cerca de su valor final.

13. sanity check. Si resultados son malos, ir eliminando las features que veamos que su valor esta lejos
	del valor que debiera tener. Si las eliminamos, deberiamos comprobar que el f score aumenta

17. Podriamos considerar lo que vimos en el paper que presento Ariel. Segun cuantos puntos hemos tenido para calcular la feature extraer
una probabilidad de que el valor final sea efectivamente el valor real. (Teorema fundamental del limite?)

Tal vez si demostramos que la media de la feature tiende a parecerse al valor final, podriamos usar directamente la ecuacion que ahi mostraban.

18. Agregar config a Features y pyRF para centralizar todas las rutas y configuraciones generales. Asi queda mas limpio el codigo en general